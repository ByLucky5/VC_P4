# PrÃ¡ctica 4 - Entrenamiento de un modelo para DetecciÃ³n de MatrÃ­culas con YOLO

Este proyecto implementa un **sistema de detecciÃ³n y seguimiento de personas y vehÃ­culos** mediante **YOLOv8/YOLO11** y el framework **Ultralytics**, con capacidad para:
- Detectar y seguir vehÃ­culos y personas en vÃ­deo.  
- Detectar matrÃ­culas en vehÃ­culos mediante un modelo entrenado propio.  
- Anonimizar personas y matrÃ­culas en la visualizaciÃ³n final.  
- Generar un **CSV con los resultados** de detecciÃ³n y seguimiento.  
- Calcular el **flujo direccional** (izquierda/derecha) de personas y vehÃ­culos.

---

## ğŸ“ Estructura del Proyecto

â”œâ”€â”€ dataset/
â”‚ â”œâ”€â”€ train/
â”‚ â”‚ â”œâ”€â”€ images/
â”‚ â”‚ â””â”€â”€ labels/
â”‚ â”œâ”€â”€ val/
â”‚ â”‚ â”œâ”€â”€ images/
â”‚ â”‚ â””â”€â”€ labels/
â”‚ â””â”€â”€ test/
â”‚ â”œâ”€â”€ images/
â”‚ â””â”€â”€ labels/
â”‚
â”œâ”€â”€ data.yaml
â”œâ”€â”€ yolo_runs/
â”‚ â””â”€â”€ plates_detection/ # Carpeta generada tras entrenamiento del detector de matrÃ­culas
â”‚ â””â”€â”€ weights/
â”‚ â””â”€â”€ best.pt
â”œâ”€â”€ VC_P4.ipynb # Cuaderno con la resoluciÃ³n de la primera parte de la prÃ¡ctica
â”œâ”€â”€ VC_P4b.ipynb # Cuaderno con la resoluciÃ³n de la segunda parte (OCR)
â”œâ”€â”€ C0142.mp4 # VÃ­deo de test (no incluido por tamaÃ±o)
â”œâ”€â”€ p4_output.mp4 # VÃ­deo resultante con detecciones (enlace externo)
â”œâ”€â”€ p4_results.csv # Resultados de detecciÃ³n y tracking
â”œâ”€â”€ p4_flujo.csv # Resultados del flujo final
â””â”€â”€ README.md

---

## âš™ï¸ 1. ConfiguraciÃ³n del Entorno

Requiere un entorno Python con soporte CUDA (En nuestro caso: CUDA 12.7).

* Instalar Python 3.9.5.
* Ejecutar los siguientes comandos en una terminal, con permisos de administrador

### InstalaciÃ³n paso a paso

```bash
# === Crear el entorno virtual ===
python -m venv VC_P4

# === Activar el entorno ===
.\VC_P4\Scripts\activate

# === Instalar PyTorch compatible con CUDA 12.x ===
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121  # o cu126

# === Instalar Ultralytics (YOLOv11) ===
pip install ultralytics

# === Instalar OpenCV ===
pip install opencv-python

# === Instalar lap (para el tracking en YOLO) ===
pip install lap
```

---

## Entrenamiento del Modelo para Detectar MatrÃ­culas

Una vez recopiladas y anotadas las imÃ¡genes, se deben organizar correctamente antes del entrenamiento con YOLO.

### Estructura de datos

```
dataset/
â”œâ”€â”€ images/
â””â”€â”€ labels/
```

* `images/`: contiene las imÃ¡genes de entrada
* `labels/`: contiene los archivos `.txt` homÃ³nimos con las anotaciones

Cada archivo `.txt` contiene las anotaciones en formato YOLO:

```
<object-class-id> <x> <y> <width> <height>
```

Donde:

| Campo             | DescripciÃ³n                                                        |
| ----------------- | ------------------------------------------------------------------ |
| `object-class-id` | Identificador numÃ©rico de la clase (por ejemplo, `0` para â€œplateâ€) |
| `x`, `y`          | Coordenadas del **centro del contenedor**, normalizadas            |
| `width`, `height` | Dimensiones del contenedor, tambiÃ©n normalizadas                   |

---

### DivisiÃ³n del dataset

Se realizÃ³ una divisiÃ³n aleatoria mediante el script `divide.py`:

| Conjunto      | Porcentaje | NÂº de imÃ¡genes |
| ------------- | ---------- | -------------- |
| Entrenamiento | 70%        | 483            |
| ValidaciÃ³n    | 20%        | 138            |
| Test          | 10%        | 70             |

---

### Archivo `data.yaml`

El archivo de configuraciÃ³n `data.yaml` define las rutas del dataset y las clases:

```yaml
train: dataset/train/images
val: dataset/val/images
test: dataset/test/images

nc: 1
names: ['plate']
```

---

### Entrenamiento

El entrenamiento puede realizarse tanto en **CPU** como en **GPU**:

```bash
# === CPU ===
yolo detect train data=data.yaml model=yolo11n.pt imgsz=416 batch=4 device=cpu epochs=40 project=yolo_runs name=plates_detection exist_ok=True

# === GPU ===
yolo detect train data=data.yaml model=yolo11n.pt imgsz=416 batch=4 device=0 epochs=40 project=yolo_runs name=plates_detection exist_ok=True
```

---

### ValidaciÃ³n y PredicciÃ³n

```bash
# ValidaciÃ³n
yolo detect val model=yolo_runs/plates_detection/train/weights/best.pt data=data.yaml

# PredicciÃ³n sobre imÃ¡genes o vÃ­deo
yolo detect predict model=yolo_runs/plates_detection/weights/best.pt source=dataset/test/images/
yolo detect predict model=yolo_runs/plates_detection/weights/best.pt source="C0142.mp4"
```


## DetecciÃ³n, Seguimiento y AnonimizaciÃ³n (`p4.py`)

El script `p4.py` realiza todo el pipeline de detecciÃ³n y seguimiento.

### Funcionalidades

* Detecta **personas y vehÃ­culos** con el modelo general `yolo11n.pt`
* Detecta **matrÃ­culas** con el modelo entrenado `best.pt`
* Realiza **tracking persistente** para mantener el `track_id`
* **Anonimiza** personas y matrÃ­culas con desenfoque (`cv2.GaussianBlur`)
* Genera:

  * Un vÃ­deo procesado (`p4_output.mp4`)
  * Un CSV con todas las detecciones (`p4_results.csv`)
  * 
---

### Formato del CSV generado

Si detecta matrÃ­cula:
| frame | tipo_objeto | confianza | track_id | x1  | y1  | x2  | y2  | plate_conf | mx1 | my1 | mx2 | my2 |
| ----- | ----------- | --------- | -------- | --- | --- | --- | --- | ---------- | --- | --- | --- | --- |
| 10    | car         | 0.89      | 2        | 120 | 310 | 280 | 420 | 0.93       | 140 | 360 | 250 | 400 |


Si no detecta matrÃ­cula:
| frame | tipo_objeto | confianza | track_id | x1  | y1  | x2  | y2  | plate_conf | mx1 | my1 | mx2 | my2 |
| ----- | ----------- | --------- | -------- | --- | --- | --- | --- | ---------- | --- | --- | --- | --- |
| 27    | car         | 0.78      | 5        | 56 | 234 | 134 | 346 | ,       | , | , | , | , |

---

## AnÃ¡lisis del Flujo Direccional (`p4_flujo.py`)

El flujo direccional no se calcula durante la inferencia, sino **a partir del CSV generado**.

### ğŸ“‹ Proceso

1. Se lee el archivo `p4_results.csv`.
2. Se calcula el **centro de cada detecciÃ³n**:

   ```python
   cx = (x1 + x2) // 2
   ```
3. Se registra el primer y Ãºltimo centro de cada `track_id`.
4. Se determina la direcciÃ³n del movimiento:

   * â¡ï¸ **derecha** si `cx_final > cx_inicial`
   * â¬…ï¸ **izquierda** si `cx_final < cx_inicial`
   * â¹ï¸ **estÃ¡tica** si no hay desplazamiento significativo
5. Se genera un **CSV resumen final**: `p4_flujo.csv`

---

### â–¶ï¸ EjecuciÃ³n

```bash
python p4_flujo.py
```

---

### Formato del CSV

| track_id | tipo_objeto | confianza | flujo     |
| -------- | ----------- | --------- | --------- |
| 1        | car         | 0.91      | derecha   |
| 2        | person      | 0.88      | izquierda |
| 3        | bus         | 0.95      | estatica  |

---

## Videos

### Video de test
([Enlace al video](https://alumnosulpgc-my.sharepoint.com/personal/mcastrillon_iusiani_ulpgc_es/_layouts/15/stream.aspx?id=%2Fpersonal%2Fmcastrillon%5Fiusiani%5Fulpgc%5Fes%2FDocuments%2FRecordings%2FC0142%2EMP4&ga=1&referrer=StreamWebApp%2EWeb&referrerScenario=AddressBarCopied%2Eview%2E46ab14ca%2D810e%2D4502%2Db4e6%2D24d9e9c97e7e))

### Video procesado (AnonimizaciÃ³n)
<p align="center">
  <a href="https://www.youtube.com/watch?v=X" target="_blank">
    <img src="https://img.youtube.com/vi/X/0.jpg" alt="Video anonimizaciÃ³n" width="480">
  </a>
</p>

# PrÃ¡ctica 4b â€“ Reconocimiento de texto en matrÃ­culas (OCR)

En la segunda parte de la prÃ¡ctica (P4b) se amplia el sistema para incluir **reconocimiento de texto (OCR)** en las matrÃ­culas, comparando:

* **EasyOCR**
* **Tesseract**
* **PaddleOCR**
* **SmolVLM** (modelo de lenguaje visual)

Esta parte se desarrolla en el cuaderno `VC_P4b.ipynb`.
