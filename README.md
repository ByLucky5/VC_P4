# Pr√°ctica 4 - Detecci√≥n de Matr√≠culas con YOLO

Pr√°ctica realizada por el grupo 15 (Luc√≠a Motas Guedes y Ra√∫l Marrero Marichal).

Este proyecto implementa un **sistema de detecci√≥n y seguimiento de personas y veh√≠culos** mediante **YOLOv8/YOLO11** y el framework **Ultralytics**, con capacidad para:
- Detectar y seguir veh√≠culos y personas en v√≠deo.  
- Detectar matr√≠culas en veh√≠culos mediante un modelo entrenado propio.  
- Anonimizar personas y matr√≠culas en la visualizaci√≥n final.  
- Generar un **CSV con los resultados** de detecci√≥n y seguimiento.  
- Calcular el **flujo direccional** (izquierda/derecha) de personas y veh√≠culos.

---

## Estructura del Proyecto

```bash
‚îú‚îÄ‚îÄ dataset/
‚îÇ ‚îú‚îÄ‚îÄ train/
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ images/
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ labels/
‚îÇ ‚îú‚îÄ‚îÄ val/
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ images/
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ labels/
‚îÇ ‚îî‚îÄ‚îÄ test/
‚îÇ ‚îú‚îÄ‚îÄ images/
‚îÇ ‚îî‚îÄ‚îÄ labels/
‚îÇ
‚îú‚îÄ‚îÄ data.yaml
‚îú‚îÄ‚îÄ yolo_runs/
‚îÇ ‚îî‚îÄ‚îÄ plates_detection/ # Carpeta generada tras entrenamiento del detector de matr√≠culas
‚îÇ ‚îî‚îÄ‚îÄ weights/
‚îÇ ‚îî‚îÄ‚îÄ best.pt
‚îú‚îÄ‚îÄ VC_P4.ipynb # Cuaderno con la resoluci√≥n de la primera parte de la pr√°ctica
‚îú‚îÄ‚îÄ VC_P4b.ipynb # Cuaderno con la resoluci√≥n de la segunda parte (OCR)
‚îú‚îÄ‚îÄ C0142.mp4 # V√≠deo de test (enlace externo)
‚îú‚îÄ‚îÄ p4_output.mp4 # V√≠deo resultante con detecciones (enlace externo)
‚îú‚îÄ‚îÄ p4_results.csv # Resultados de detecci√≥n y tracking
‚îú‚îÄ‚îÄ p4_flujo.csv # Resultados del flujo final
‚îî‚îÄ‚îÄ README.md
```
> Nota: Los v√≠deos no han sido incluidos en el repositorio porque superan el tama√±o permitido y el dataset se encuentra disponible en google drive.

---

## 1. Configuraci√≥n del Entorno

Requiere un entorno Python con soporte CUDA (En nuestro caso: CUDA 12.7).

* Instalar Python 3.9.5.
* Ejecutar los siguientes comandos en una terminal, con permisos de administrador.

### Instalaci√≥n paso a paso

```bash
# === Crear el entorno virtual ===
python -m venv VC_P4

# === Activar el entorno ===
.\VC_P4\Scripts\activate

# === Instalar PyTorch compatible con CUDA 12.x ===
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121  # o cu126

# === Instalar Ultralytics (YOLOv11) ===
pip install ultralytics

# === Instalar OpenCV ===
pip install opencv-python

# === Instalar lap (para el tracking en YOLO) ===
pip install lap
```

---

## 2. Entrenamiento del Modelo para Detectar Matr√≠culas

Una vez recopiladas y anotadas las im√°genes, se deben organizar correctamente antes del entrenamiento con YOLO.

### Estructura de datos

```
dataset/
‚îú‚îÄ‚îÄ images/
‚îî‚îÄ‚îÄ labels/
```

* `images/`: contiene las im√°genes de entrada.
* `labels/`: contiene los archivos `.txt` hom√≥nimos con las anotaciones.

Cada archivo `.txt` contiene las anotaciones en formato YOLO:

```
<object-class-id> <x> <y> <width> <height>
```

Donde:

| Campo             | Descripci√≥n                                                        |
| ----------------- | ------------------------------------------------------------------ |
| `object-class-id` | Identificador num√©rico de la clase (por ejemplo, `0` para ‚Äúplate‚Äù). |
| `x`, `y`          | Coordenadas del **centro del contenedor**, normalizadas.            |
| `width`, `height` | Dimensiones del contenedor, tambi√©n normalizadas.                   |

---

### Divisi√≥n del dataset (([Enlace al repositorio](https://drive.google.com/drive/folders/1FaHHGn4XlpjYOFe-2kCk8cHs3wnOyZk6)

Se dispon√≠a de 691 im√°genes y se realiz√≥ una divisi√≥n aleatoria mediante el script `divide.py`:

| Conjunto      | Porcentaje | N¬∫ de im√°genes |
| ------------- | ---------- | -------------- |
| Entrenamiento | 70%        | 483            |
| Validaci√≥n    | 20%        | 138            |
| Test          | 10%        | 70             |

---

### Archivo `data.yaml`

El archivo de configuraci√≥n `data.yaml` define las rutas del dataset y las clases:

```yaml
train: dataset/train/images
val: dataset/val/images
test: dataset/test/images

nc: 1
names: ['plate']
```

---

### Entrenamiento

El entrenamiento puede realizarse tanto en **CPU** como en **GPU**:

```bash
# === CPU ===
yolo detect train data=data.yaml model=yolo11n.pt imgsz=416 batch=4 device=cpu epochs=40 project=yolo_runs name=plates_detection exist_ok=True

# === GPU ===
yolo detect train data=data.yaml model=yolo11n.pt imgsz=416 batch=4 device=0 epochs=40 project=yolo_runs name=plates_detection exist_ok=True
```

---

### Validaci√≥n y Predicci√≥n

```bash
# Validaci√≥n
yolo detect val model=yolo_runs/plates_detection/train/weights/best.pt data=data.yaml

# Predicci√≥n sobre im√°genes o v√≠deo
yolo detect predict model=yolo_runs/plates_detection/weights/best.pt source=dataset/test/images/
yolo detect predict model=yolo_runs/plates_detection/weights/best.pt source="C0142.mp4"
```


## 3. Detecci√≥n, Seguimiento y Anonimizaci√≥n (`p4.py`)

El script `p4.py` realiza todo el pipeline de detecci√≥n y seguimiento.

### Funcionalidades

* Detecta **personas y veh√≠culos** con el modelo general `yolo11n.pt`
* Detecta **matr√≠culas** con el modelo entrenado `best.pt`
* Realiza **tracking persistente** para mantener el `track_id`
* **Anonimiza** personas y matr√≠culas con desenfoque (`cv2.GaussianBlur`)
* Genera:

  * Un v√≠deo procesado (`p4_output.mp4`)
  * Un CSV con todas las detecciones (`p4_results.csv`)
  * 
---

### Formato del CSV generado

Si detecta matr√≠cula:
| frame | tipo_objeto | confianza | track_id | x1  | y1  | x2  | y2  | plate_conf | mx1 | my1 | mx2 | my2 |
| ----- | ----------- | --------- | -------- | --- | --- | --- | --- | ---------- | --- | --- | --- | --- |
| 10    | car         | 0.89      | 2        | 120 | 310 | 280 | 420 | 0.93       | 140 | 360 | 250 | 400 |


Si no detecta matr√≠cula:
| frame | tipo_objeto | confianza | track_id | x1  | y1  | x2  | y2  | plate_conf | mx1 | my1 | mx2 | my2 |
| ----- | ----------- | --------- | -------- | --- | --- | --- | --- | ---------- | --- | --- | --- | --- |
| 27    | car         | 0.78      | 5        | 56 | 234 | 134 | 346 | ,       | , | , | , | , |

---

## 4. An√°lisis del Flujo Direccional (`p4_flujo.py`)

El flujo direccional no se calcula durante la inferencia, sino **a partir del CSV generado**.

### üìã Proceso

1. Se lee el archivo `p4_results.csv`.
2. Se calcula el **centro de cada detecci√≥n**:

   ```python
   cx = (x1 + x2) // 2
   ```
3. Se registra el primer y √∫ltimo centro de cada `track_id`.
4. Se determina la direcci√≥n del movimiento:

   * ‚û°Ô∏è **derecha** si `cx_final > cx_inicial`
   * ‚¨ÖÔ∏è **izquierda** si `cx_final < cx_inicial`
   * ‚èπÔ∏è **est√°tica** si no hay desplazamiento significativo
5. Se genera un **CSV resumen final**: `p4_flujo.csv`

---

### Formato del CSV

| track_id | tipo_objeto | confianza | flujo     |
| -------- | ----------- | --------- | --------- |
| 1        | car         | 0.91      | derecha   |
| 2        | person      | 0.88      | izquierda |
| 3        | bus         | 0.95      | estatica  |

---

## 5. Videos

### Video de test
([Enlace al video](https://alumnosulpgc-my.sharepoint.com/personal/mcastrillon_iusiani_ulpgc_es/_layouts/15/stream.aspx?id=%2Fpersonal%2Fmcastrillon%5Fiusiani%5Fulpgc%5Fes%2FDocuments%2FRecordings%2FC0142%2EMP4&ga=1&referrer=StreamWebApp%2EWeb&referrerScenario=AddressBarCopied%2Eview%2E46ab14ca%2D810e%2D4502%2Db4e6%2D24d9e9c97e7e))

### Video procesado (Anonimizaci√≥n)
<p align="center">
  <a href="https://www.youtube.com/watch?v=367ghZkLyX0" target="_blank">
    <img src="https://img.youtube.com/vi/367ghZkLyX0/0.jpg" alt="Video anonimizaci√≥n" width="480">
  </a>
</p>

# Pr√°ctica 4b ‚Äì Reconocimiento de texto en matr√≠culas (OCR)

En la segunda parte de la pr√°ctica (P4b) se amplia el sistema para incluir **reconocimiento de texto (OCR)** en las matr√≠culas, comparando:

* **EasyOCR**
* **Tesseract**
* **PaddleOCR**
* **SmolVLM** (modelo de lenguaje visual)

Esta parte se desarrolla en el cuaderno `VC_P4b.ipynb`.
